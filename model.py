import torch.nn as nn
import torch
from torch.optim import Adam

device = torch.device('cpu')
if torch.cuda.is_available():
    device = device('cuda')
print(device)


class DCGAN(nn.Module):

    def __init__(self, generator, discriminator, input_size):
        super(DCGAN, self).__init__()
        self.generator = generator
        self.discriminator = discriminator
        self.input_size = input_size
        self.criterion = nn.BCELoss()

    def forward(self, input):
        """
        This function implements the main procedure
        to train the DCGAN. It is mainly composed by two
        practical steps which will improve the convergence
        during training, as suggested by https://github.com/soumith/ganhacks.
        1- maximize the quantity log(D(x)) + log(1-(D(G(z))) for the Discriminator
        2- maximize the quantity log(D(G(z))) for the Generator.
        :param input: batch of images sampled from the dataset
        :return d_loss, g_loss: the losses generated by the discriminator and the generator respectively.
        """
        batch_size = input.shape[0]
        # Because we are using the BCE, by alternating
        # labels of zeros and ones, we can easily compute
        # the two terms of the first equation and then sum those
        # values, thus maximizing the loss.

        # Train Discriminator --> Maximize: log(D(x)) + log(1-(D(G(z)))

        d_loss, gen_imgs = self.train_discriminator(input)

        # train Generator --> Maximize: log(D(G(z)))

        g_loss = self.train_generator(gen_imgs)

        return d_loss, g_loss

    def train_generator(self, gen_imgs):
        self.generator.optim.zero_grad()
        self.generator.train()

        # classify previous Generator's output
        pred_gen = self.discriminator(gen_imgs).reshape(-1)
        # use the real labels to compute the loss
        real_labels = torch.ones(pred_gen.shape, dtype=torch.float).to(device)
        # we use the real labels because we want to maximize the quantity log(D(G(z)))
        # instead of minimizing the quantity log(1-(D(G(z)))
        # because we use the BCEloss, this is achieved by considering the quantity log(x)
        # instead of the quantity log(1-x)
        g_loss = self.criterion(pred_gen, real_labels)
        # compute gradients
        g_loss.backward()
        # update weights
        self.generator.optim.step()

        return g_loss


    def train_discriminator(self, input):

        self.discriminator.optim.zero_grad()
        self.discriminator.train()

        batch_size = input.shape[0]

        fake_z_vectors = torch.randn(batch_size, self.input_size, 1, 1).to(device)

        # get loss for the real images --> log(D(x))
        pred_real = self.discriminator(input).reshape(-1)
        # create vector of 1s for the real images. Must be of the same shape as pred_real
        real_labels = torch.ones(pred_real.shape, dtype=torch.float).to(device)
        real_img_loss = self.criterion(pred_real, real_labels)
        # compute gradients
        real_img_loss.backward()

        # get loss for the fake images --> log(1-(D(G(z)))

        # generate fake images from batch of latent vectors
        gen_imgs = self.generator(fake_z_vectors).detach()
        # forward pass through the discriminator to get predictions
        pred_gen = self.discriminator(gen_imgs).reshape(-1)
        # create vector of 0s for the generated images. Must be of the same shape as pred_gen
        fake_label = torch.zeros(pred_gen.shape, dtype=torch.float).to(device)
        gen_img_loss = self.criterion(pred_gen, fake_label)
        # compute gradients
        gen_img_loss.backward()

        # combine the two losses
        d_loss = real_img_loss + gen_img_loss
        # update weights
        self.discriminator.optim.step()

        return d_loss, gen_imgs


class Discriminator(nn.Module):
    """
    This class implements the Discriminator of the DCGAN. We followed the
    guidelines expressed in the following paper of Alec Radford, Luke Metz and Soumith Chintala
    https://arxiv.org/pdf/1511.06434.pdf.
    """
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(

            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),
            nn.Sigmoid()
        ).to(device)

        self.optim = Adam(self.model.parameters(), lr=0.0002, betas=(0.5, 0.999))
        self.init_weights()


    def forward(self, x):
        output = self.model(x)
        return output

    def init_weights(self):
        print('...Initialize weights from N(0, 0.02)...')
        for layer in self.model:
            layer_type = type(layer)
            if layer_type == nn.Conv2d or layer_type == nn.BatchNorm2d:
                nn.init.normal_(layer.weight, 0, 0.02)
        print('Weights initialized.')


class Generator(nn.Module):
    """
    This class implements the Generator of the DCGAN following the guidelines
    detailed expressed in the following paper of Alec Radford, Luke Metz and Soumith Chintala
    https://arxiv.org/pdf/1511.06434.pdf.
    """

    def __init__(self, z_size):
        super(Generator, self).__init__()
        self.z_size = z_size
        # the sequence of [Conv Transpose-BatchNorm-Act Function] used to generate
        # a volume of 3x64x64 (an image) from the latent vector. To compute the correct
        # output dimensions at each layer we apply the formula [out = (in +2p - k]/s) + 1]
        self.model = nn.Sequential(

            nn.ConvTranspose2d(self.z_size, 512, kernel_size=4, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),
            nn.Tanh()
        ).to(device)

        self.optim = Adam(self.model.parameters(), lr=0.0002, betas=(0.5, 0.999))
        self.init_weights()

    def forward(self, z):
        output = self.model(z)
        return output

    def init_weights(self):
        print('...Initialize weights from N(0, 0.02)...')
        for layer in self.model:
            layer_type = type(layer)
            if layer_type == nn.ConvTranspose2d or layer_type == nn.BatchNorm2d:
                nn.init.normal_(layer.weight, 0, 0.02)
        print('Weights initialized.')
